{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation for Graph Classification\n",
    "\n",
    "In this notebook, we test the Consistency of explanations - if inputs are identical, then we expect the explanations to be identical "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have ran the explainer for the same set of graphs twice and we have the explanations of each round in separate csv files. First we load these files into two datatframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"syn6_round1.csv\",usecols=[\"Weights of regression\",\"Bias of regression\"])\n",
    "df2 = pd.read_csv(\"syn6_round2.csv\",usecols=[\"Weights of regression\",\"Bias of regression\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_numpy(d):\n",
    "    \"\"\"The first column in both dataframes are arrays but saved as a string.\n",
    "    This function converts it to a float array\n",
    "\n",
    "    Args:\n",
    "        d (str): array of weights stored in csv as string\n",
    "\n",
    "    Returns:\n",
    "        numpy array: array of weights\n",
    "    \"\"\"\n",
    "    s = d.split(']')\n",
    "    s = s[0].split()\n",
    "    s = s[1:]\n",
    "    a = []\n",
    "\n",
    "    for c in s:\n",
    "        if c != '[' and c!=']':\n",
    "            a.append(float(c))\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded the data, now we wish to measure the how close the explanations are. For this we first give some notations:\n",
    "\n",
    "- a1: numpy array of weights along bias of regression from df1\n",
    "- a2: numpy array of weights along bias of regression from df2\n",
    "\n",
    "Next, to quantify this closeness, similar to the coherence we define the following metric\n",
    "\n",
    "![alt text](consistency_formula.png \"Title\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(A):\n",
    "    \"\"\"Normalize array A\n",
    "\n",
    "    Args:\n",
    "        A (numpy array): array to normalize\n",
    "\n",
    "    Returns:\n",
    "        numpy array: normalized array\n",
    "    \"\"\"\n",
    "    scale_factor = A.max() - A.min()\n",
    "    B = np.ones_like(A)*A.min()\n",
    "\n",
    "    A = (A - B)/scale_factor\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_vector(df_num,i):\n",
    "    \"\"\"Prepare vector for further calculations\n",
    "\n",
    "    Args:\n",
    "        df_num (str): decides if data from df1 or df2\n",
    "        i (int): Index in the datafram\n",
    "\n",
    "    Returns:\n",
    "        numpy array: array of weights along with the bias\n",
    "    \"\"\"\n",
    "    df = eval('df'+df_num)      # Get the dataframe df1 or df2\n",
    "    a = convert_to_numpy(df['Weights of regression'][i])\n",
    "    a.append(df[\"Bias of regression\"][i])\n",
    "    a = np.array(a)\n",
    "\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closeness: 1.0 +/- 0.0\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "\n",
    "closeness = []\n",
    "for i in range(len(df1)):\n",
    "    # Form numpy arrays a1 and a2 by appending corresponding biases to the list of weights\n",
    "    a1 = prep_vector('1',i)\n",
    "    a2 = prep_vector('2',i)\n",
    "\n",
    "    # print(f\"a1: {a1}\")\n",
    "    # print(f\"a2: {a2}\")\n",
    "    # Normalize the vectors\n",
    "    a1 = normalize(a1)\n",
    "    a2 = normalize(a2)\n",
    "\n",
    "    # Evaluating the required metric\n",
    "    a = (np.linalg.norm(a1 - a2, 2)**2)\n",
    "\n",
    "    closeness.append(2/(1 + math.exp(a)))\n",
    "\n",
    "closeness = np.array(closeness)\n",
    "mean = np.mean(closeness)\n",
    "std = np.std(closeness)\n",
    "\n",
    "print(f\"Closeness: {mean} +/- {std}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
